	var aDataSet = [
		/* auto-generated - START */
		['1','Amazon Geospatial','AWS Awazon Public Data','Image - Satellite Imagery','144 datasets','https://registry.opendata.aws/',],
		['2','Berkeley Computer Vision Group','Contour Detection and Image Segmentation Resources','Image','500','https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html',],
		['3','Chinese University of Hong Kong  Multimedia Laboratory  Datasets','The Chinese University of Hongkng (CUHK) Multimedia Lab (MMLab) is one of the pioneering institutes on deep learning. In GPU Technology Conference (GTC) 2016, a world-wide technology summit, the lab is recognized as one of the top ten AI pioneers, and listed together with top research groups in the world (e.g. MIT, Stanford, Berkeley, and Univ. of Toronto).','Image','12 datasets','http://mmlab.ie.cuhk.edu.hk/datasets.html',],
		['4','CIFAR-10','For image classification. It consists of 60,000 images of 10 classes (each class is represented as a row in the above image). In total, there are 50,000 training images and 10,000 test images. The dataset is divided into 6 parts � 5 training batches and 1 test batch. Each batch has 10,000 images.','Image','60000','http://www.cs.toronto.edu/~kriz/cifar.html',],
		['5','Common Objects in COntext (COCO)','COCO is a large-scale object detection, segmentation, and captioning dataset. COCO has several features: Object segmentation, Recognition in context, Superpixel stuff segmentation, 330K images (>200K labeled), 1.5 million object instances, 80 object categories, 91 stuff categories, 5 captions per image, 250,000 people with keypoints','Image','330000','http://cocodataset.org/#home',],
		['6','Company Logo','Flickr logo','Image','32 and 47 classes','https://www.uni-augsburg.de/en/fakultaet/fai/informatik/prof/mmc/research/datensatze/flickrlogos/',],
		['7','Computer Vision Online','','Image','','https://computervisiononline.com/datasets, https://www.aitribune.com/dataset',],
		['8','CreativeCommons - Animal Diversity Web ','','Image','15554','https://animaldiversity.org ',],
		['9','CreativeCommons - Behance ','','Image','6479672','https://www.behance.net ',],
		['10','CreativeCommons - Brooklyn Museum ','','Image','61503','https://www.brooklynmuseum.org ',],
		['11','CreativeCommons - Culturally Authentic Pictorial Lexicon ','','Image','15142','http://capl.washjeff.edu ',],
		['12','CreativeCommons - Cleveland Museum of Art ','','Image','32643','http://www.clevelandart.org ',],
		['13','CreativeCommons - DeviantArt ','','Image','271362','https://www.deviantart.com ',],
		['14','CreativeCommons - Digitalt Museum ','','Image','266672','https://digitaltmuseum.no ',],
		['15','CreativeCommons - Flickr ','','Image','349021635','https://www.flickr.com ',],
		['16','CreativeCommons - Flora-On ','','Image','55010','https://flora-on.pt ',],
		['17','CreativeCommons - Geograph Britain and Ireland ','','Image','1244387','https://www.geograph.org.uk ',],
		['18','CreativeCommons - McCord Museum ','','Image','218720','http://www.musee-mccord.qc.ca/en ',],
		['19','CreativeCommons - Metropolitan Museum of Art ','','Image','500738','https://www.metmuseum.org ',],
		['20','CreativeCommons - Museums Victoria ','','Image','85575','https://museumsvictoria.com.au ',],
		['21','CreativeCommons - PhyloPic ','','Image','3463','http://phylopic.org ',],
		['22','CreativeCommons - Rawpixel ','','Image','63550','https://www.rawpixel.com ',],
		['23','CreativeCommons - Rijksmuseum ','','Image','29999','https://www.rijksmuseum.nl/en ',],
		['24','CreativeCommons - Sketchfab ','','Image','37903','https://sketchfab.com ',],
		['25','CreativeCommons - SVG Silh ','','Image','276966','https://svgsilh.com ',],
		['26','CreativeCommons - Thingiverse ','','Image','29624','https://www.thingiverse.com ',],
		['27','CreativeCommons - Thorvaldsens Museum ','','Image','8912','http://www.thorvaldsensmuseum.dk ',],
		['28','CreativeCommons - Wikimedia Commons ','','Image','23749024','https://commons.wikimedia.org ',],
		['29','CreativeCommons - World Register of Marine Species ','','Image','23716','http://www.marinespecies.org ',],
		['30','DeepGlint Microsoft ','Face Feature Test/Trillion Pairs, 1) Web Face Recognition Training Datasets=CASIA-Webface (10K ids/0.5M images), CelebA (10K ids/0.2M images), UMDFace (8K ids/0.37M images), VGG2 (9K ids/3.31M images), MS1M-IBUG (85K ids/3.8M images), MS1M-ArcFace (85K ids/5.8M images), Asian-Celeb (94K ids/2.8M images), DeepGlint (181K ids/6.75M images), IMDB-Face (59K ids/1.7M images), Celeb500k (500K ids/50M images), MegaFace (672K ids/4.7M images) 2) Face Recognition Validation Datasets=CFP-FP (500 ids/7K images/7K pairs), AgeDB-30 (570 ids/12,240 images/6K pairs),LFW (5749 ids/13233 images/6K pairs), CALFW (5749 ids/13233 images/6K pairs), CPLFW (5749 ids/13233 images/6K pairs), 3) Face Recognition Image Test  Datasets=MegaFace, IJB (IJB-B, IJB-C), TrillionPairs, NIST,  4) Face Recognition Video Test Datasets=YTF, IQIYI','Image','','http://trillionpairs.deepglint.com/data, https://github.com/deepinsight/insightface/wiki/Dataset-Zoo',],
		['31','ETH','Zurich Building Image Database ','Image','','http://www.vision.ee.ethz.ch/showroom/zubud/',],
		['32','Face Dataset','','Image','','https://github.com/topics/face-dataset, https://github.com/jian667/face-dataset',],
		['33','Flickr-Faces-HQ Dataset (FFHQ)',' Flickr-Faces-HQ (FFHQ) is a high-quality image dataset of human faces, originally created as a benchmark for generative adversarial networks (GAN)','Image','','https://github.com/NVlabs/ffhq-dataset/blob/master/README.md',],
		['34','Flickr images','MIRFLICKR-1M has 1 million Flickr images (CC Licence), MIRFLICKR25000 has 25,000 Flickr images (CC Licence)','Image','','http://press.liacs.nl/mirflickr/',],
		['35','Generated Photos - faces','Generated photos are created from scratch by AI systems. All images can be used for any purpose without worrying about copyrights, distribution rights, infringement claims, or royalties. The AI-produced images are intended to be used as design elements in anything from presentations to websites and mobile apps. Everything is free to use with link attribution back to generated.photos.','Image','','https://drive.google.com/drive/folders/1wSy4TVjSvtXeRQ6Zr8W98YbSuZXrZrgY',],
		['36','German Traffic Sign Recognition','Currently, there are two data sets available, the German Traffic Sign Recognition Benchmark (GTSRB), a large multi-category classification benchmark, and the German Traffic Sign Detection Benchmark (GTSDB). The first was used in a competition at IJCNN 2011. ','Image','50,000, 43 classes','https://generated.photos/faces, http://benchmark.ini.rub.de/, https://github.com/topics/german-traffic-sign-classifier',],
		['37','Google Open Images dataset','Open Images is a dataset of ~9M images that have been annotated with image-level labels, object bounding boxes and visual relationships. The training set of V4 contains 14.6M bounding boxes for 600 object classes on 1.74M images, making it the largest existing dataset with object location annotations. ','Image','9 million','https://storage.googleapis.com/openimages/web/index.html',],
		['38','Google Quickdraw','The Quick Draw Dataset is a collection of 50 million drawings across 345 categories, contributed by players of the game Quick, Draw!. The drawings were captured as timestamped vectors, tagged with metadata including what the player was asked to draw and in which country the player was located. You can browse the recognized drawings on quickdraw.withgoogle.com/data.','Image','50 million, 345 categories','https://github.com/googlecreativelab/quickdraw-dataset',],
		['39','ImageCLEF - The CLEF Cross Language Image Retrieval Track','ImageCLEF aims to provide an evaluation forum for the cross�language annotation and retrieval of images. Motivated by the need to support multilingual users from a global community accessing the ever growing body of visual information, the main goal of ImageCLEF is to support the advancement of the field of visual media analysis, indexing, classification, and retrieval, by developing the necessary infrastructure for the evaluation of visual information retrieval systems operating in both monolingual, cross�language and language-independent contexts. ImageCLEF aims at providing reusable resources for such benchmarking purposes.','Image','20000','https://www.imageclef.org/datasets, https://www.imageclef.org/photodata',],
		['40','ImageNet','ImageNet is a dataset of images that are organized according to the WordNet hierarchy. WordNet contains approximately 100,000 phrases and ImageNet has provided around 1000 images on average to illustrate each phrase.','Image','1000','http://www.image-net.org/',],
		['41','Kairos','60 Facial Recognition Databases','Image','60 datasets','https://www.kairos.com/blog/60-facial-recognition-databases',],
		['42','Mapillary Vistas Dataset ','A diverse street-level imagery dataset with pixel-accurate and instance-specific human annotations for understanding street scenes around the world.  25,000 high-resolution images, 152 object categories, 100 instance-specifically annotated categories, Global reach, covering 6 continents, Variety of weather, season, time of day, camera, and viewpoint. ','Image','25000','https://www.mapillary.com/dataset/vistas?pKey=rwbBtYKofke2NeLIvj8j-A&lat=20&lng=0&z=1.5, https://github.com/parachutel/deeplabv3plus_on_Mapillary_Vistas',],
		['43','Microsoft Celeb (MS-Celeb-1M)','Microsoft Celeb (MS-Celeb-1M) is a dataset of 10 million face images harvested from the Internet for the purpose of developing face recognition technologies.  According to Microsoft Research, who created and published the dataset in 2016, MS Celeb is the largest publicly available face recognition dataset in the world, containing over 10 million images of nearly 100,000 individuals. Microsoft s goal in building this dataset was to distribute an initial training dataset of 100,000 individuals  biometric data to accelerate research into recognizing a larger target list of one million people "using all the possibly collected face images of this individual on the web as training data"','Image','10  million, 100000 individuals','https://megapixels.cc/msceleb/, https://github.com/EB-Dodo/C-MS-Celeb',],
		['44','MIT-Adobe FiveK Dataset','Adjusting photographs to obtain compelling renditions requires skill and time. Even contrast and brightness adjustments are challenging because they require taking into account the image content. Photographers are also known for having different retouching preferences. As the result of this complexity, rule-based, one-size-fits-all automatic techniques often fail. This problem can greatly benefit from supervised machine learning but the lack of training data has impeded work in this area. Our first contribution is the creation of a high-quality reference dataset. We collected 5,000 photos, manually annotated them, and hired 5 trained photographers to retouch each picture. The result is a collection of 5 sets of 5,000 example input-output pairs that enable supervised learning. ','Image','5000','https://data.csail.mit.edu/graphics/fivek/',],
		['45','NUS - Real-World Web Image Dataset from National University of Singapore','A web image dataset created by Lab for Media Search in National University of Singapore. The dataset includes: (1) 269,648 images and the associated tags from Flickr, with a total number of 5,018 unique tags; (2) six types of low-level features extracted from these images, including 64-D color histogram, 144-D color correlogram, 73-D edge direction histogram, 128-D wavelet texture, 225-D block-wise color moments and 500-D bag of words based on SIFT descriptions; and (3) ground-truth for 81 concepts that can be used for evaluation. Based on this dataset, we identify several research issues on web image annotation and retrieval. We also provide the baseline results for web image annotation by learning from the tags using the traditional k-NN algorithm. The benchmark results show that it is possible to learn models from these data to help general image retrieval. ','Image','269,648','https://lms.comp.nus.edu.sg/research/NUS-WIDE.htm',],
		['46','Open Images Dataset','Open Images is a dataset of almost 9 million URLs for images. These images have been annotated with image-level labels bounding boxes spanning thousands of classes. The dataset contains a training set of 9,011,219 images, a validation set of 41,260 images and a test set of 125,436 images.','Image','9 million','https://github.com/openimages/dataset',],
		['47','Street View House Numbers (SVHN) ','SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. ','Image','73257 digits for training, 26032 digits for testing, and 531131 additional','http://ufldl.stanford.edu/housenumbers/',],
		['48','Tencent ML-Images','ML-Images: the largest open-source multi-label image database, including 17,609,752 training and 88,739 validation image URLs, which are annotated with up to 11,166 categories. Resnet-101 model: it is pre-trained on ML-Images, and achieves the top-1 accuracy 80.73% on ImageNet via transfer learning','Image','18 million images and 11 000 classes','https://github.com/Tencent/tencent-ml-images',],
		['49','VisualData','Computer Vision Datasets','Image','','https://www.visualdata.io/',],
		['50','VisualQA (VQA)','VQA is a new dataset containing open-ended questions about images. These questions require an understanding of vision, language and commonsense knowledge to answer.    Contains 265,016 images (COCO and abstract scenes), At least 3 questions (5.4 questions on average) per image, 10 ground truth answers per question, 3 plausible (but likely incorrect) answers per question.','Image','265,016 images (COCO and abstract scenes)','https://visualqa.org/',],
		['51','Yahoo','One Hundred Million Creative Commons Flickr Images for Research. The dataset (about 12GB) consists of a photo_id, a jpeg url or video url, and some corresponding metadata such as the title, description, title, camera type, title, and tags. Plus about 49 million of the photos are geotagged! What�s not there, like comments, favorites, and social network data, can be queried from the Flickr API.','Image','100 million','https://yahooresearch.tumblr.com/post/89783581601/one-hundred-million-creative-commons-flickr-images',],
		/* auto-generated - END */
	];


$(document).ready(function() {	$('#dynamic').html( '<table cellpadding="0" style="width:100%" cellspacing="0" border="0" class="display" id="example"></table>' );
	$('#example').dataTable( {
		"aaData": aDataSet,
		"aoColumns": [
			{ "sTitle": "S/N", "sWidth": "2%" },
			{ "sTitle": "Name", "sWidth": "10%" },
			{ "sTitle": "Description", "sWidth": "10%" },
			{ "sTitle": "Type", "sWidth": "2%" },
			{ "sTitle": "Records", "sWidth": "2%" },
			{ "sTitle": "URL", "sWidth": "10%" },
		]
		} );
	} );
